# Lasso prior for softmax classifier

## Set environment and import data

```{r}
rm(list=ls())
install.packages("rjags")
install.packages("ggplot2")
install.packages("patchwork")
library("ggplot2")
library(patchwork)
library(rjags)
library(coda)
```

Importing useful functions

```{r}
source("utils_functions.R")
```

```{r}
wine = readRDS(file="./data/wine.Rda")
df = remove_outliers(wine)
df = to_one_hot(df)
df
```
Generate training set
```{r}
indexes = sample(1:nrow(df), size=0.4*nrow(df))
train <- df[indexes,]
test <- df[-indexes,]
df <- train
```


```{r}
Y = df[,!names(df) %in% names(wine), drop=T]
X = as.matrix(df[,names(df) %in% names(wine), drop=F])
```

$$ \begin{align*}
  Y_{ij} \mid p_{ij} \sim \mathcal{Categorical}(p_i)\\
  p_{ij} \mid \alpha_i, \beta_i = \text{softmax}(\alpha_i + X_i \beta_i)\\

  \alpha_i, \beta_i \sim \mathcal{DE}(0, \sigma^2)\\
  \sigma^2 \sim \mathcal{IG}(\alpha_{\mathcal{DE}}, \beta_{\mathcal{DE}})
\end{align*} $$
where $$\alpha_{\mathcal{DE}}, \beta_{\mathcal{DE}}$$ are the hyperparameters that must be chosen.

```{r}
model_string <- textConnection("model{
  # Likelihood
  for (i in 1:N){
    Y[i,] ~ dmulti(p[i, ], 1)                          # sample from categorical
    for (j in 1:M) {
      exp_z[i,j] <- exp(z[i, j])                  # softmax function
      p[i, j]    <- exp_z[i, j]/sum(exp_z[i, ])   # softmax function
      z[i, j]    <- beta[j, ] %*% X[i, ]          # linear model
    }
  }
  # Priors
  for (j in 1: M){
    for (k in 1: K){
      beta[j, k] ~ ddexp(0, inv.var^2)            # Lasso prior
    }
  }
  inv.var ~ dgamma(alpha_hp, beta_hp)
  sigma = inv.var
}")
```

```{r}
N <- dim(X)[1]  # number of observations
K <- dim(X)[2]  # number of covariates
M <- 10         # number of categories

# hyperparameters 
alpha_hp = 0.01
beta_hp = 0.01
data <-list(Y=Y, X=X, N=N, M=M, K=K, alpha_hp=alpha_hp, beta_hp=beta_hp)

burn     <- 5000
n.iter   <- 10000
thin     <- 5
n.chains <- 2

### run the chain
model <- jags.model(model_string,data = data, n.chains=n.chains,quiet=FALSE)
update(model, burn, progress.bar="none")
samples <- coda.samples(model, variable.names=c("beta","sigma", "p"), thin=thin, n.iter=n.iter)
```
